{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances are: [1. 3. 0. 2. 3.]\n",
      "k_nearest_neighbor_indices are : [2 0 3 1]\n",
      "classes of nearest neighbors are: [5 6 4 7]\n",
      "KNN with n = 1: 5\n",
      "KNN with n = 4: 5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[1., 1., 1., 1.],\n",
    "[1., 1., 0., 0.], \n",
    "[0., 1., 1., 1.], \n",
    "[0., 0., 1., 0.],\n",
    "[1., 0., 1., 0.]]).reshape(-1,4)\n",
    "\n",
    "## can NOT select a reordered subset with lists y_train[[1,2]] but with numpy arrays we can!\n",
    "y_train = np.array([6, 7, 5, 4, 3]) \n",
    "test = np.array([0., 1., 1., 1.]) \n",
    "# Homegrown KNN\n",
    "\n",
    "distances_matrix_vec = np.linalg.norm(X_train - test, ord=1, axis=1)\n",
    "print(f\"distances are: {distances_matrix_vec}\")\n",
    "k_nearest_neighbor_indices = np.argsort(distances_matrix_vec)[:4]\n",
    "print(f\"k_nearest_neighbor_indices are : {k_nearest_neighbor_indices}\")\n",
    "print(f\"classes of nearest neighbors are: {y_train[k_nearest_neighbor_indices]}\")\n",
    "class_knn_1 = y_train[k_nearest_neighbor_indices][0]\n",
    "class_knn_4 = y_train[k_nearest_neighbor_indices][0:4].mean()\n",
    "\n",
    "print(f\"KNN with n = 1: {class_knn_1}\")\n",
    "print(f\"KNN with n = 4: {class_knn_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.6 -2.8 -4.4  7.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([1, 2, 1, 2])\n",
    "w=np.array([4,-2,-4, 8])\n",
    "eta = .05\n",
    "y = 4\n",
    "gradient = np.dot(X.dot(w)-y,X)\n",
    "w = w - eta * gradient \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([1, 2, 1, 2])\n",
    "w=np.array([2,-1,-2, 4])\n",
    "y = 4\n",
    "#####\n",
    "yhat = np.dot(X,w)\n",
    "MSE =  np.square(yhat-y)\n",
    "#####\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.25 -3.15 -5.1   6.5 ]\n",
      "[ 3.43 -2.97 -4.74  6.86]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X1=np.array([1, 2, 1, 2])\n",
    "X2=np.array([1, 1, 2, 2])\n",
    "w=np.array([4,-2,-4, 8])\n",
    "eta = .05\n",
    "y1 = 4\n",
    "y2 = 3\n",
    "###\n",
    "\n",
    "# BATCH #\n",
    "w0 = w - eta * np.dot(np.dot(X1,w)-y1,X1) - eta * np.dot(np.dot(X2,w)-y2,X2)\n",
    "\n",
    "# SOCHASTIC #\n",
    "w =w- eta * np.dot(np.dot(X1,w)-y1,X1)\n",
    "w =w- eta * np.dot(np.dot(X2,w)-y2,X2)\n",
    "###\n",
    "print(w0)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Loss 5.05\n",
      "Lasso Loss 4.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X1=np.array([1, 2, 1, 2])\n",
    "X2=np.array([1, 1, 2, 2])\n",
    "w=np.array([2,-1,-2, 4])\n",
    "alpha = 0.1\n",
    "y1 = 4\n",
    "y2 = 3\n",
    "#####\n",
    "ridge_loss = 1/2  * (np.square(np.dot(X1,w)-y1) + np.square(np.dot(X2,w)-y2)) + (alpha *.5 *np.sum(np.square(w[1:])))\n",
    "lasso_loss = 1/2  * (np.square(np.dot(X1,w)-y1) + np.square(np.dot(X2,w)-y2)) + (alpha * np.sum(np.abs(w[1:])))\n",
    "#####\n",
    "print(f\"Ridge Loss {ridge_loss.sum()}\")\n",
    "print(f\"Lasso Loss {lasso_loss.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class  bad  good  very\n",
       "d1      0    0     1     0\n",
       "d2      1    0     1     1\n",
       "d3      1    1     1     0\n",
       "d4      0    1     0     1\n",
       "d5      1    1     1     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_priors: [0.4 0.6]\n",
      "[1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>d3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bad  good  very\n",
       "d3    1     1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood Pr(d6|ham): 0.037037037037037035\n",
      "likelihood Pr(d6|SPAM): 0.03606311044327573\n",
      "unnormalized Pr(D6|ham)*Pr(ham) is : 0.01481\n",
      "unnormalized Pr(D6|SPAM)*Pr(SPAM) is : 0.02164\n",
      "Posterior Probabilities in % is: Pr(Ham|D6) is :      41\n",
      "Posterior Probabilities in % is: Pr(SPAM|D6) is :      59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "vocabulary = [\"bad\", \"good\", \"very\"]\n",
    "\n",
    "# Document by term matrix\n",
    "doc_per_term= np.array([[0, 1, 0 ],\n",
    "[0, 1, 1],\n",
    "[1, 1, 0],\n",
    "[1, 0, 1],\n",
    "[1, 1, 2]])\n",
    "# y_train\n",
    "# 0 for Ham and 1 for spam\n",
    "class_per_doc= np.array([0,1,1,0,1])\n",
    "display(pd.DataFrame(np.c_[class_per_doc, doc_per_term], index = [\"d1\", \"d2\",\"d3\", \"d4\", \"d5\"],\n",
    "columns = [\"Class\"]+ vocabulary))\n",
    "\n",
    "## Learn the Naïve Bayes Classification\n",
    "##\n",
    "##\n",
    "model_priors = np.bincount(class_per_doc)/ len(class_per_doc)\n",
    "print(f\"model_priors: {model_priors}\")\n",
    "print (np.sum(doc_per_term[class_per_doc==0,:],axis=0))\n",
    "#=========================================================#\n",
    "# Place your code between here #\n",
    "# Please adapt the following code to accomplish this task #\n",
    "#\n",
    "# Calculate Pr(w_i|ham) aka ham class conditionals\n",
    "model_data_given_ham = (1 + np.sum(doc_per_term[class_per_doc==0],axis=0))/(np.sum(doc_per_term[class_per_doc==0]) + len(vocabulary))\n",
    "# Calculate Pr(w_i|ham) aka SPAM class conditionals\n",
    "model_data_given_spam = (1 + np.sum(doc_per_term[class_per_doc==1],axis=0))/(np.sum(doc_per_term[class_per_doc==1]) + len(vocabulary))\n",
    "# #\n",
    "# When asked to copy/paste your code in the homework #\n",
    "# submission quiz, only submit the code you added #\n",
    "# (or modified) between the comment blocks #\n",
    "#==========================================================#\n",
    "\n",
    "# Test document terms are:\n",
    "# bad, good, very\n",
    "d6 = [1, 1, 1] #TEST DOCUMENT\n",
    "display(pd.DataFrame([d6], index = [\"d3\"], columns = vocabulary))\n",
    "\n",
    "## Naïve Bayes Classification\n",
    "## Likelihood\n",
    "## Applying the Unigram Language Model\n",
    "# Calculate Posterior Probabilities using the learnt Naive Bayes Model\n",
    "#\n",
    "print(f\"likelihood Pr(d6|ham): {np.prod(np.power(model_data_given_ham, d6))}\")\n",
    "print(f\"likelihood Pr(d6|SPAM): {np.prod(np.power(model_data_given_spam, d6))}\")\n",
    "\n",
    "pr_ham = np.prod(np.power(model_data_given_ham, d6)) * model_priors[0]\n",
    "pr_spam = np.prod(np.power(model_data_given_spam, d6))* model_priors[1]\n",
    "print(f\"unnormalized Pr(D6|ham)*Pr(ham) is : {pr_ham:7.5f}\")\n",
    "print(f\"unnormalized Pr(D6|SPAM)*Pr(SPAM) is : {pr_spam:7.5f}\")\n",
    "\n",
    "print(f\"Posterior Probabilities in % is: Pr(Ham|D6) is : {100*pr_ham/(pr_spam+pr_ham):7.0f}\")\n",
    "print(f\"Posterior Probabilities in % is: Pr(SPAM|D6) is : {100*pr_spam/(pr_spam+pr_ham):7.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for w1 is : 7.00000\n",
      "score for w2 is : -9.00000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w1 = [-1, 2, 3]\n",
    "w2 = [-7,-4, 1]\n",
    "X = [1,1,2]\n",
    "#modify here\n",
    "d1 = np.dot(X,w1)\n",
    "d2 = np.dot(X,w2)\n",
    "#######\n",
    "print(f\"score for w1 is : {d1:7.5f}\")\n",
    "print(f\"score for w2 is : {d2:7.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949\n"
     ]
    }
   ],
   "source": [
    "print(f'{np.round((- np.log(1-.5) - np.log(.3))/2, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,1,0], [1,1,3], [1,2,4], [1,1,2]]).reshape(-1,3)\n",
    "w = np.array([1,-2,1])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "\n",
    "p_hat = 1/ (1 + np.exp(-np.dot(X,w)))\n",
    "\n",
    "CXE_loss = (-1/X.shape[0]) * np.sum((y * np.log(p_hat)) + (1-y) * np.log(1-p_hat))\n",
    "print(f\"{CXE_loss:5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    1.2s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVTrain_MAE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Exp_Desc</th>\n",
       "      <th>Model</th>\n",
       "      <th>Hyperparams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44.177</td>\n",
       "      <td>46.525</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>std</td>\n",
       "      <td>KNN</td>\n",
       "      <td>weighted=distance, k_nn=11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CVTrain_MAE    Test_MAE   Dataset Exp_Desc Model                 Hyperparams\n",
       "0      44.177      46.525  Diabetes      std   KNN  weighted=distance, k_nn=11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "dataset_name = \"Diabetes\"\n",
    "ds = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds.data, ds.target,\n",
    "                                                    random_state=0)\n",
    "\n",
    "#=========================================================#\n",
    "# Place your code between here                            #\n",
    "# Please adapt the following code to accomplish this task #\n",
    "params = {'knn__n_neighbors':list(range(1,16)),\n",
    "         'knn__weights': ['distance','uniform']}\n",
    "pipeline = Pipeline([\n",
    "    ('knn',KNeighborsRegressor())\n",
    "])\n",
    "grid = GridSearchCV(pipeline,params,cv=5,verbose=1,n_jobs=-1,refit=True,scoring=\"neg_mean_absolute_error\")\n",
    "grid.fit(X_train,y_train)\n",
    "#                                                          #\n",
    "# When asked to copy/paste your code in the homework       # \n",
    "# submission quiz, only submit the code you added          #\n",
    "# (or modified) between the comment blocks                 #\n",
    "#==========================================================#\n",
    "\n",
    "n, wgt = grid.best_params_['knn__n_neighbors'], grid.best_params_['knn__weights']\n",
    "\n",
    "# experiment table of results\n",
    "# del experimentLog\n",
    "try: experimentLog \n",
    "except : experimentLog = pd.DataFrame(columns=[ \"CVTrain_MAE\", \"Test_MAE\", \"Dataset\", \n",
    "                                               \"Exp_Desc\", \"Model\", \"Hyperparams\"])\n",
    "experimentLog.loc[len(experimentLog)] =[f\"{-grid.best_score_:10.3f}\", \n",
    "                                        f\"{-grid.score(X_test, y_test):10.3f}\", \n",
    "                                        dataset_name, \"std\", \"KNN\",\n",
    "                                        f\"weighted={wgt}, k_nn={n}\"]\n",
    "display(experimentLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
