# -*- coding: utf-8 -*-
"""Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kPFWLPp35xqnfCzcY6nAythej2RS043o
"""

import warnings
warnings.filterwarnings('ignore')

import fbprophet
import pandas as pd
import numpy as np
import matplotlib
matplotlib.style.use('ggplot')
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from statsmodels.tsa.stattools import adfuller
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# merging begins here #
df = pd.read_csv('main_meter_reads.csv')
df.head()

df_2020 = pd.read_csv('file.csv')
df_2020.head()

# interpolate 2020 data
df_2020["READ_DTM"] = pd.to_datetime(df_2020["READ_DTM"], format='%m/%d/%Y %H:%M')
df_2020 = df_2020.groupby(['METER_ID',pd.Grouper(key='READ_DTM', freq='30min')]).sum()[["READ_VALUE"]].reset_index()
df_2020.head()

weather_2020 = pd.read_csv('IU weather 2020.csv')
weather_2020["date"] = pd.to_datetime(weather_2020["date"], format='%m/%d/%Y %H:%M')
weather_2020.head()

# join 2020 weather with 2020 meter data
df_2020["date_string"] = df_2020["READ_DTM"].astype(str)
weather_2020["date_string"] = weather_2020["date"].astype(str)
df_2020 = pd.merge(weather_2020, df_2020, how ='left', on ='date_string')

# 617 null values, drop them
df_2020.dropna(axis=0,inplace=True)

# join campus meter data
df_2020 = df_2020[["METER_ID","READ_VALUE","date_string","date","temp","humidity","dew_point"]]
df = df[["METER_ID","READ_VALUE","date_string","date","temp","humidity","dew_point"]]

merged = pd.concat([df, df_2020],axis=0)
merged.tail()

# drop all null rows
merged.dropna(axis=1,how="all",inplace=True)
merged.isnull().sum()

null_columns = merged[merged.isnull().any(axis=1)]
null_indexes = list(null_columns.index)
null_columns

# Impute missing values
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
check = merged[["temp","humidity","dew_point"]]
imputer.fit(merged[["temp","humidity","dew_point"]])
imp_values = imputer.transform(merged[["temp","humidity","dew_point"]])

# replace imputed values with 
merged[["temp","humidity","dew_point"]] = imp_values

merged.iloc[null_indexes]

# split meters into two groups
meters = list(merged.METER_ID.unique())
group1 = merged[(merged.METER_ID == meters[0]) | (merged.METER_ID == meters[1])]
group2 = merged[(merged.METER_ID != meters[0]) & (merged.METER_ID != meters[1])]

"""# EDA"""

subset = merged[["READ_VALUE","temp","humidity","dew_point"]]
sns.heatmap(subset.corr(),annot=True)
plt.title("Correlation Heatmap")

fig = px.scatter(merged, x="temp", y="READ_VALUE", color="humidity", 
                 width=2000, height=500, title="Temp Against Meter Value", facet_col="METER_ID")
fig.show()

fig = px.scatter(merged, x="humidity", y="READ_VALUE", color="temp",
                 width=2000, height=500, title="Humidity Against Meter Value", facet_col="METER_ID")
fig.show()

fig = px.scatter(merged, x="dew_point", y="READ_VALUE", color="humidity",
                 width=2000, height=500, title="Dew Point Against Meter Value", facet_col="METER_ID")
fig.show()

fig = px.line(merged,x="date",y="READ_VALUE",width=2000, height=500, color="METER_ID",title="Meter Reading Trend", facet_col="METER_ID")
fig.update_xaxes(tickangle=45)
fig.show()

"""# Stationary Data Check"""

fig = px.histogram(merged,x="READ_VALUE",width=2000, height=500, color="METER_ID",title="Meter Reading Distribution", facet_col="METER_ID")
fig.show()

# check each meter, split each meter in two, check for variance and mean shifts

def is_stationary(data):
  X = data.values
  split = round(len(X) // 2)
  X1, X2 = X[0:split], X[split:]
  mean1, mean2 = X1.mean(), X2.mean()
  var1, var2 = X1.var(), X2.var()
  return mean1, var1, mean2, var2

ans1 = is_stationary(check1)
ans2 = is_stationary(check2)
ans3 = is_stationary(check3)
ans4 = is_stationary(check4)
ans5 = is_stationary(check5)
ans6 = is_stationary(check6)

results = [ans1,ans2,ans3,ans4,ans5,ans5]
i = 0

for result in results:
  meter_name = meters[i]
  print(f'METER: {meter_name} Mean 1: {result[0]} Mean 2: {result[2]} Var 1: {result[1]} Var 2: {result[3]}\n')
  i += 1

# plot the log value
df["log_x"] = np.log(df["READ_VALUE"])

fig = px.histogram(df,x="log_x",width=2000, height=500, color="METER_ID",title="Log Meter Reading Distribution", facet_col="METER_ID")
fig.show()

# plot log time series
fig = px.line(df,x="date",y="log_x",width=2000, height=500, color="METER_ID",title="Log Meter Reading Trend", facet_col="METER_ID")
fig.update_xaxes(tickangle=45)
fig.show()

# replace 0 values by adding constant 1, so we can take the log
check1.replace(0,1,inplace=True)
check2.replace(0,1,inplace=True)
check3.replace(0,1,inplace=True)
check4.replace(0,1,inplace=True)
check5.replace(0,1,inplace=True)
check6.replace(0,1,inplace=True)

# check similarity in mean and variance of log data
ans1 = is_stationary(np.log(check1))
ans2 = is_stationary(np.log(check2))
ans3 = is_stationary(np.log(check3))
ans4 = is_stationary(np.log(check4))
ans5 = is_stationary(np.log(check5))
ans6 = is_stationary(np.log(check6))

results = [ans1,ans2,ans3,ans4,ans5,ans5]
i = 0

for result in results:
  meter_name = meters[i]
  print(f'METER: {meter_name} Mean 1: {result[0]} Mean 2: {result[2]} Var 1: {result[1]} Var 2: {result[3]}\n')
  i += 1

"""## Augmented Dickey Fuller Test
* p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.
* p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.

If the test statistic is negative, you are more likely to reject the null hypothesis
"""

# convert original data
check1, check2, check3 = df1["READ_VALUE"], df2["READ_VALUE"], df3["READ_VALUE"]
check4, check5, check6 = df4["READ_VALUE"], df5["READ_VALUE"], df6["READ_VALUE"]

# Ad-fuller root test
def adfuller_test(data):
  X = data.values
  result = adfuller(X)
  return result

ans1 = adfuller_test(check1)
ans2 = adfuller_test(check2)
ans3 = adfuller_test(check3)
ans4 = adfuller_test(check4)
ans5 = adfuller_test(check5)
ans6 = adfuller_test(check6)

results = [ans1,ans2,ans3,ans4,ans5,ans6]

i = 0

for result in results:
  meter_name = meters[i]
  print(f'METER: {meter_name} Stat: {result[0]} p_value: {result[1]}\n')
  i += 1

"""All meters except for 4440104 appears to be  non-stationary. I would consider this meter and edge case since it has a negative statistic.

# Univariate Model (Meter 4440012)
"""

# prep data
sample_df1 = df1[["date","READ_VALUE"]]
sample_df1.columns = ["ds","y"]
model = fbprophet.Prophet()

# data model
model.fit(sample_df1)
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)

forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()

fig1 = model.plot(forecast)

fig1 = model.plot_components(forecast)

"""# Multivariate Model"""

merged

group1_subset = group1[["date","READ_VALUE","temp","humidity","dew_point"]]
group1_subset.columns = ["ds","y","temp","humidity","dew_point"]
model = fbprophet.Prophet()

# add regressors, fit model
model.add_regressor('temp')
model.add_regressor('humidity')
model.add_regressor('dew_point')
model.fit(group1_subset)

group1_subset.tail()

# add regressors, make prediction
future = model.make_future_dataframe(periods=240, freq='30T')
print(future)
#future['temp'] = merged["temp"]
#future['humidity'] = merged['humidity']
#future['dew_point'] = merged['dew_point']

# drop nans
#future.dropna(inplace=True)

# make prediction
#forecast = model.predict(future)
#forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()
#future

# at a certain point in time, some sort of metric

fig2 = model.plot(forecast)

fig2 = model.plot_components(forecast)