{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETbDH5iwAWlA"
   },
   "outputs": [],
   "source": [
    "! pip install pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahMPLk2MLO-Y",
    "outputId": "97589b93-66ad-453a-84a2-c8b694df9a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNi8d-Gs-nBY"
   },
   "outputs": [],
   "source": [
    "METER_DIR = \"/content/drive/My Drive/meters/\" #'./data/meter_data/'\n",
    "WEATHER_DIR = \"/content/drive/My Drive/weather/\" #'./data/weather_data/'\n",
    "MAIN_METERS = \"/content/drive/My Drive/main_meter_reads.csv\" # until we get raw 20208-2019 data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pyowm\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "godW5r8tAbTE"
   },
   "outputs": [],
   "source": [
    "# Load main meter data files - all the same format - Andrea can just add additional files / replace files\n",
    "############################################\n",
    "\n",
    "# NOTE: This crawls through the meter directory to get all files\n",
    "list_meter = []\n",
    "meters = os.listdir(METER_DIR)\n",
    "\n",
    "# loop through meters directory\n",
    "for meter in meters: # to avoid ipynb checkpoints\n",
    "  if meter != '.ipynb_checkpoints':\n",
    "    df = pd.read_csv(METER_DIR+meter, index_col=None, header=0)\n",
    "    list_meter.append(df)\n",
    "\n",
    "df_meter = pd.concat(list_meter, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "f-Qdsz0-C6WM",
    "outputId": "c4af45b0-f5f2-49db-953b-51bfd5895db1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METER_ID</th>\n",
       "      <th>READ_DTM</th>\n",
       "      <th>READ_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377584</th>\n",
       "      <td>4440177</td>\n",
       "      <td>2020-11-01 21:30:00</td>\n",
       "      <td>2681.461548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377585</th>\n",
       "      <td>4440177</td>\n",
       "      <td>2020-11-01 22:00:00</td>\n",
       "      <td>2591.665161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377586</th>\n",
       "      <td>4440177</td>\n",
       "      <td>2020-11-01 22:30:00</td>\n",
       "      <td>2568.092651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377587</th>\n",
       "      <td>4440177</td>\n",
       "      <td>2020-11-01 23:00:00</td>\n",
       "      <td>2551.837403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377588</th>\n",
       "      <td>4440177</td>\n",
       "      <td>2020-11-01 23:30:00</td>\n",
       "      <td>2523.771850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        METER_ID            READ_DTM   READ_VALUE\n",
       "377584   4440177 2020-11-01 21:30:00  2681.461548\n",
       "377585   4440177 2020-11-01 22:00:00  2591.665161\n",
       "377586   4440177 2020-11-01 22:30:00  2568.092651\n",
       "377587   4440177 2020-11-01 23:00:00  2551.837403\n",
       "377588   4440177 2020-11-01 23:30:00  2523.771850"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "#\n",
    "# Group sum the data by 30 minutes.\n",
    "#\n",
    "############################################\n",
    "\n",
    "df_meter[\"READ_DTM\"] = pd.to_datetime(df_meter[\"READ_DTM\"], format='%m/%d/%Y %H:%M')\n",
    "df_meter = df_meter.groupby(['METER_ID',pd.Grouper(key='READ_DTM', offset='0min', closed='right', freq='30min')]).sum()[[\"READ_VALUE\"]].reset_index()\n",
    "df_meter.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "44n0kRtLFfv0",
    "outputId": "f0194584-27e2-45b9-b907-4382a0d2c0dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43994</th>\n",
       "      <td>BMG</td>\n",
       "      <td>2020-11-16 21:53</td>\n",
       "      <td>54.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>32.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43995</th>\n",
       "      <td>BMG</td>\n",
       "      <td>2020-11-16 22:53</td>\n",
       "      <td>52.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>34.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43996</th>\n",
       "      <td>BMG</td>\n",
       "      <td>2020-11-16 23:53</td>\n",
       "      <td>50.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>37.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station             valid   tmpf   dwpf   relh\n",
       "43994     BMG  2020-11-16 21:53  54.00  25.00  32.26\n",
       "43995     BMG  2020-11-16 22:53  52.00  25.00  34.72\n",
       "43996     BMG  2020-11-16 23:53  50.00  25.00  37.39"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weather data files - reread the updates files\n",
    "############################################\n",
    "\n",
    "# Add the pulled weather data to the dataframe\n",
    "list_weather = []\n",
    "weather = os.listdir(WEATHER_DIR)\n",
    "\n",
    "# loop through weather directory\n",
    "for w in weather: # to skip ipynb file that is first in the directory\n",
    "    if w != '.ipynb_checkpoints': # we can remove this once this is a python file\n",
    "      # this file was cleaned up, so we don't need to skiprows\n",
    "      if w == 'BMG_hist.txt':\n",
    "        df = pd.read_csv(WEATHER_DIR+w, index_col=None, header=0)\n",
    "        list_weather.append(df)\n",
    "      # we need to skip the first 5 rows in the text file\n",
    "      else:\n",
    "        df = pd.read_csv(WEATHER_DIR+w, index_col=None, header=0,skiprows=5)\n",
    "        list_weather.append(df)\n",
    "\n",
    "hist_weather = pd.concat(list_weather, axis=0, ignore_index=True)\n",
    "hist_weather.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
    "hist_weather.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmsOFTQLmZOK"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "\n",
    "# Historical weather data is already uploaded\n",
    "\n",
    "############################################\n",
    "#\n",
    "# Get the last weather data since the last date\n",
    "#\n",
    "############################################\n",
    "hist_weather[\"valid_dt\"] = pd.to_datetime(hist_weather[\"valid\"], format='%Y/%m/%d %H:%M')\n",
    "last_date = hist_weather[\"valid_dt\"].max()\n",
    "last_date = datetime.utcfromtimestamp(datetime.timestamp(last_date))\n",
    "yesterday = datetime.utcfromtimestamp(datetime.timestamp(datetime.now()+timedelta(days = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2RVDp5Bnxcb"
   },
   "outputs": [],
   "source": [
    "# Number of attempts to download data\n",
    "MAX_ATTEMPTS = 6\n",
    "# HTTPS here can be problematic for installs that don't have Lets Encrypt CA\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "NETWORK = 'IN_ASOS'\n",
    "STATION = 'BMG'\n",
    "\n",
    "\n",
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    print(uri)\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lM6Zvz0nziF"
   },
   "outputs": [],
   "source": [
    "def get_weather_history(startts, endts):\n",
    "    \"\"\"\n",
    "    This function gets the defined weather station's tempurature, dewpoint\n",
    "    and relative humidity for the date range specified in UTC and then \n",
    "    writes to a file in the format STATION_FromDate_ToDate.txt.\n",
    "    Inputs:\n",
    "        startts:    Starting Timestamp in UTC to request data for\n",
    "        endts:      Ending Timestamp in UTC\n",
    "    \"\"\"\n",
    "\n",
    "    service = SERVICE + \"data=tmpf&data=relh&data=dwpf&tz=Etc/UTC&format=comma&latlon=no&\"\n",
    "\n",
    "    service += startts.strftime(\"year1=%Y&month1=%m&day1=%d&\")\n",
    "    service += endts.strftime(\"year2=%Y&month2=%m&day2=%d&\")\n",
    "    \n",
    "    station = STATION\n",
    "    uri = \"%s&station=%s\" % (service, station)\n",
    "    print(\"Downloading: %s\" % (station,))\n",
    "    data = download_data(uri)\n",
    "    outfn = WEATHER_DIR + \"%s_%s_%s.txt\" % (\n",
    "        station,\n",
    "        startts.strftime(\"%Y%m%d%H%M\"),\n",
    "        endts.strftime(\"%Y%m%d%H%M\"),\n",
    "    )\n",
    "    out = open(outfn, \"w\")\n",
    "    out.write(data)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2y-xTfPOE8QG"
   },
   "outputs": [],
   "source": [
    "# retrieve forecast data\n",
    "recent_data = get_weather_history(startts=last_date, endts=yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foOYB-UmXDYe"
   },
   "outputs": [],
   "source": [
    "# Load weather data files - reread the updates files\n",
    "############################################\n",
    "\n",
    "# Add the pulled weather data to the dataframe\n",
    "list_weather = []\n",
    "weather = os.listdir(WEATHER_DIR)\n",
    "\n",
    "# loop through weather directory\n",
    "for w in weather: # to skip ipynb file that is first in the directory\n",
    "    if w != '.ipynb_checkpoints': # we can remove this once this is a python file\n",
    "      # this file was cleaned up, so we don't need to skiprows\n",
    "      if w == 'BMG_hist.txt':\n",
    "        df = pd.read_csv(WEATHER_DIR+w, index_col=None, header=0)\n",
    "        list_weather.append(df)\n",
    "      # we need to skip the first 5 rows in the text file\n",
    "      else:\n",
    "        df = pd.read_csv(WEATHER_DIR+w, index_col=None, header=0,skiprows=5)\n",
    "        list_weather.append(df)\n",
    "\n",
    "hist_weather = pd.concat(list_weather, axis=0, ignore_index=True)\n",
    "hist_weather[[\"tmpf\",\"dwpf\",\"relh\"]] = hist_weather[[\"tmpf\",\"dwpf\",\"relh\"]].replace('M',np.nan)\n",
    "hist_weather['tmpf'] = pd.to_numeric(hist_weather['tmpf'])\n",
    "hist_weather['dwpf'] = pd.to_numeric(hist_weather['dwpf'])\n",
    "hist_weather['relh'] = pd.to_numeric(hist_weather['relh'])\n",
    "hist_weather['DTTM'] = pd.to_datetime(hist_weather['valid'])\n",
    "hist_weather.index = hist_weather['DTTM']\n",
    "hist_weather.drop(columns=['Unnamed: 0','station', 'valid', 'DTTM'], inplace=True)\n",
    "hist_weather = hist_weather.resample('0.5H').mean().interpolate(method='time')\n",
    "hist_weather = hist_weather.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORmo3E-FD1bc"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "#\n",
    "# Calculate a rate column (double the usage)\n",
    "#\n",
    "#  NOTE:  This needs work - I grabbed it from the Peak Demand Fcst (AH).ipynb notebook which did some\n",
    "#   basic manipulation to get the dataset working, so df refers to main_meter_reads and df_2020 refers\n",
    "#   to the 2020_campus master meters.csv and weather_2020 is the IU weather 2020.csv file that Eric made.\n",
    "#\n",
    "#  OK - this is out of order, because this is working with the old main_meter_reads, which has the\n",
    "#  KWH_RATE in the READ_VALUE column and already has weather data, while the raw meter files from\n",
    "#  Andrea contain the actual READ_VALUE which we (after summing to 30 minutes) double to produce a\n",
    "#  KWH_RATE column.  This is messed up a bit because we don't have the raw files from 2018/2019, just\n",
    "#  the main_meter_reads.csv.  Also, that file messed with the dates, because it is missing some data\n",
    "#  for Daylight Savings, yet it appears that the raw data Andrea provides is in EST (not EDT - there \n",
    "#  are 24 hours in every day).  The weather data comes in UTC, so you have to adjust 5 hours to get to \n",
    "#  EST.\n",
    "#\n",
    "############################################\n",
    "\n",
    "# Join weather with meter data\n",
    "df_meter[\"date_string\"] = df_meter[\"READ_DTM\"].astype(str)\n",
    "hist_weather[\"date_string\"] = hist_weather[\"DTTM\"].astype(str)\n",
    "df_agg = pd.merge(df_meter, hist_weather, how ='left', on ='date_string')\n",
    "\n",
    "# select fields of interest\n",
    "df_agg = df_agg[[\"METER_ID\",\"READ_VALUE\",\"date_string\",\"READ_DTM\",\"tmpf\",\"dwpf\",\"relh\"]]\n",
    "\n",
    "# Add a column to hold the kWh rate (from which Peak is determined) by taking the 30\n",
    "# minute usage total and doubling it (what it would be for 60 minutes if the usage was the same)\n",
    "df_agg['KWH_RATE'] = df_agg['READ_VALUE'] * 2\n",
    "\n",
    "# Fix the outliers on Jan 1, 2019, which appears to be a doubling of the data\n",
    "df_agg.loc[df_agg['date_string'] == '2019-01-01 00:00:00', 'READ_VALUE'] = df_agg.loc[df_agg['date_string'] == '2019-01-01 00:00:00', 'READ_VALUE'] / 2\n",
    "df_agg = df_agg[[\"METER_ID\",\"READ_VALUE\",\"date_string\",\"READ_DTM\",\"tmpf\",\"dwpf\",\"relh\"]]\n",
    "\n",
    "# Add a column to hold the kWh rate (from which Peak is determined) by taking the old READ_VALUE,\n",
    "# because that's what it was.  Then make the READ_VALUE the usage for the 30 minutes by \n",
    "# cutting it in half.\n",
    "df_agg['KWH_RATE'] = df_agg['READ_VALUE']\n",
    "df_agg['READ_VALUE'] = df_agg['KWH_RATE'] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssmJXbx-VwjL"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# As of now we are dropping null values, \n",
    "#six missing, may want to improve upon it in the future\n",
    "#######################################################\n",
    "df_agg.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSbPmos0n4Yj"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "#\n",
    "# Get the forecast weather data for the next 5 days from the end of the current time.  Interpolate to every 30 minutes.\n",
    "#\n",
    "#  NOTE:  This comes from IU_Peak_Test_Dataset.py.  I have not tested this or modified it, so it will likely need to be tweaked.\n",
    "#\n",
    "############################################\n",
    "\n",
    "owm = pyowm.OWM('02d982dc96589daaeebb1a7fd826930f') # You MUST provide a valid API key\n",
    "###############################################################################\n",
    "\n",
    "# Get forecast\n",
    "fc = owm.three_hours_forecast('Bloomington,IN,US')\n",
    "f = fc.get_forecast()\n",
    "###############################################################################\n",
    "\n",
    "# Set right timezone -> I replaced datetime.now() with the latest date from the weather file\n",
    "hour_difference = round((f.get_reception_time('date').replace(tzinfo=None) - datetime.now().replace(tzinfo=None)).seconds/3600)\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pclaEEn1oDfl"
   },
   "outputs": [],
   "source": [
    "# Start Creating Dataset\n",
    "\n",
    "cols = ['datetime','date','month','day','hour','weekday','temperature','precipitation','wind_speed','humidity','conditions']\n",
    "\n",
    "df = pd.DataFrame(columns=cols, index=range(0,40))\n",
    "\n",
    "n = 0\n",
    "for weather in f: ## fix hour\n",
    "    data = [weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference), (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference)).date(), \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference)).month, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference)).day, \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference)).hour, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference)).weekday(), \n",
    "            weather.get_temperature('fahrenheit')['temp'], (0 if len(weather.get_rain()) == 0 else weather.get_rain()['3h']) + (0 if len(weather.get_snow()) == 0 else weather.get_snow()['3h']),\n",
    "            weather.get_wind()['speed'], weather.get_humidity(), weather.get_status()]  \n",
    "    df.iloc[n,:] = data\n",
    "    n += 1\n",
    "      # does it always do GMT 12/3/6/9/12/3/6/9 or does it change based on hour pull?\n",
    "      # \n",
    "\n",
    "#############33333 add date to be dropped later, and weekday and remember to add offsets to hour, day, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRS6pBWHoJ3X"
   },
   "outputs": [],
   "source": [
    "# Turn 3hr forecast to hourly\n",
    "\n",
    "df_lower = pd.DataFrame(columns=cols, index=range(0,40))\n",
    "\n",
    "n = 0\n",
    "for weather in f:\n",
    "    data = [weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1), (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1)).date(), \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1)).month, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1)).day, \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1)).hour, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference+1)).weekday(), \n",
    "            weather.get_temperature('fahrenheit')['temp'], (0 if len(weather.get_rain()) == 0 else weather.get_rain()['3h']) + (0 if len(weather.get_snow()) == 0 else weather.get_snow()['3h']),\n",
    "            weather.get_wind()['speed'], weather.get_humidity(), weather.get_status()]   \n",
    "    df_lower.iloc[n,:] = data\n",
    "    n += 1\n",
    "    \n",
    "df_higher = pd.DataFrame(columns=cols, index=range(0,40))\n",
    "\n",
    "n = 0\n",
    "for weather in f:\n",
    "    data = [weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1), (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1)).date(), \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1)).month, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1)).day, \n",
    "            (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1)).hour, (weather.get_reference_time('date').replace(tzinfo=None) - timedelta(hours=hour_difference-1)).weekday(), \n",
    "            weather.get_temperature('fahrenheit')['temp'], (0 if len(weather.get_rain()) == 0 else weather.get_rain()['3h']) + (0 if len(weather.get_snow()) == 0 else weather.get_snow()['3h']),\n",
    "            weather.get_wind()['speed'], weather.get_humidity(), weather.get_status()]   \n",
    "    df_higher.iloc[n,:] = data\n",
    "    n += 1\n",
    "\n",
    "########################################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "UtilitiesPipeline_FINAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
