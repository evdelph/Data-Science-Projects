{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "KNN is a supervised machine learning model, meaning the algorithm relies on learning from labeled data to predict a given output. KNN is a classification problem. KNN computes the distances of all data points. The distances are sorted, and the first \"k\" neighbors determines the what class the data point of interest is assigned to.\n",
    "\n",
    "For this example, we are looking at creditcard.csv to predict if a transaction was fradulent or not. There are 30 features and class labels. We will construct two KNN models, one with SKlearn and a homegrown one. The results of each one are shown below. Happy learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dataframe\n",
    "credit_cards = pd.read_csv(\"creditcard.csv\")\n",
    "credit_cards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that there are 30 columns of different features and column 31 represents the class label (y). We want to separate features (X) from the labels (y). We will use the 30 features to predict the associated class of each instance. Below shows how you can use pandas indexing to accomplish this separation.\n",
    "\n",
    "The next step is to split the data into four parts: X_train and x_test, and Y_train and y_test. To accomplish this, we will use SKlearn's train_test_split method. For this case, we are allocating 25% of our data for testing and 75% for training. Then, we will normalize the data using the MinMaxScalar to standardize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data from features and class labels\n",
    "X = credit_cards.iloc[:,1:30]\n",
    "y = credit_cards[\"Class\"]\n",
    "\n",
    "# Split up training and testing data\n",
    "subsample_rate = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "X_train, _, y_train, _ = train_test_split(X_train, y_train, stratify=y_train, train_size=subsample_rate, random_state=42)\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, stratify=y_test, train_size=subsample_rate, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a lot to consider. How many neighbors (k) will optimize our predictions? Should we use uniform or weighted distance to calculate knn? To answer this, we can use tune hyperparameters using GridSearch. The first step is to set up a dictionary of parameters you want to test out. Here we are trying to select the best combination from three parameters: k, scoring metric, and uniform or weighted distance. GridSearch will iterate over these options to determine the best set of parameters for the model.\n",
    "\n",
    "After the parameters are set-up the next step is set up a pipeline, the purpose of a pipeline is to assemble several steps that can be cross-validated together while setting different parameters (what we did in the previous step). Here, it standardizes the final estimator. We put the pipeline and parameters in the gridsearch and determine the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Set up parameters\n",
    "parameters = {\n",
    "    # Number of neighbors\n",
    "    'knn__n_neighbors': list(range(1,11)),\n",
    "    # Numeric value denotes a scoring metric\n",
    "    'knn__p': list(range(1,4)),\n",
    "    # Uniform or weighted distance\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Set up pipeline\n",
    "pipe = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('knn',knn)\n",
    "])\n",
    "\n",
    "# Set up Gridsearch\n",
    "knn_gs = GridSearchCV(pipe,parameters,cv=10,n_jobs=-1,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardize',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('knn',\n",
       "                                        KNeighborsClassifier(algorithm='auto',\n",
       "                                                             leaf_size=30,\n",
       "                                                             metric='minkowski',\n",
       "                                                             metric_params=None,\n",
       "                                                             n_jobs=None,\n",
       "                                                             n_neighbors=5, p=2,\n",
       "                                                             weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'knn__p': [1, 2, 3],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with our new gridsearch, we will fit our training today to find the best hyperparameter combination and display the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=8, p=1,\n",
       "                                      weights='distance'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct parameter search, find best estimator\n",
    "knn_gs.fit(X_train, y_train)\n",
    "knn_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_true, y_pred = y_test, knn_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make predictions and store the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>K (Neighbors)</th>\n",
       "      <th>P (Scoring Metric)</th>\n",
       "      <th>Weights</th>\n",
       "      <th>Training Accuracy Score</th>\n",
       "      <th>Testing Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.998771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model K (Neighbors) P (Scoring Metric)   Weights  \\\n",
       "0  KNN Classifier             8                  1  distance   \n",
       "\n",
       "   Training Accuracy Score  Testing Accuracy Score  \n",
       "0                 0.999605                0.998771  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture results in dataframe\n",
    "results = pd.DataFrame(columns=[\"Model\",\"K (Neighbors)\",\"P (Scoring Metric)\", \"Weights\", \n",
    "                                \"Training Accuracy Score\",\"Testing Accuracy Score\"])\n",
    "results.loc[len(results)] = [\"KNN Classifier\", knn_gs.best_params_['knn__n_neighbors'],knn_gs.best_params_['knn__p'],\n",
    "                             knn_gs.best_params_['knn__weights'], knn_gs.best_score_ ,accuracy_score(y_true, y_pred)]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y-pred</th>\n",
       "      <th>Y-true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5696 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y-pred  Y-true\n",
       "0          0       0\n",
       "1          0       0\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          0       0\n",
       "...      ...     ...\n",
       "5691       0       0\n",
       "5692       0       0\n",
       "5693       0       0\n",
       "5694       0       0\n",
       "5695       0       0\n",
       "\n",
       "[5696 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "prediction_results = pd.DataFrame([y_pred,y_true]).T\n",
    "prediction_results.columns = [\"Y-pred\",\"Y-true\"]\n",
    "prediction_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing data and conducting hyperparameter tuning, we achieved a high accuracy score for both our training and testing data. We performed slightly better with the training set, but we scored over 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homegrown KNN\n",
    "\n",
    "Can we achieve similar results without using SKlearn? To test this out, we will construct KNN from scratch (homegrown) in an object oriented style. The parameters include the \"k\", the scoring function, and whether we will use distance or uniform weights. We have to re-load and restandardize our data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "\n",
    "    def __init__(self, k_neighbors=8, p=1,d_type=\"weighted\"):\n",
    "        self.k_neighbors=k_neighbors\n",
    "        self.p = p\n",
    "        self.training_data = np.array([])\n",
    "        self.training_labels = np.array([])\n",
    "        self.d_type=d_type\n",
    "        \n",
    "    def distance(self,x1,x2,d_type):\n",
    "        if d_type == \"uniform\":\n",
    "            return np.linalg.norm(x1-x2, ord=self.p, axis=1)\n",
    "        else:\n",
    "            distances = 1/np.linalg.norm(x1-x2, ord=self.p, axis=1)\n",
    "            distances[distances > 1e308] = 0\n",
    "            return distances\n",
    "    \n",
    "    def accuracy(self,y_true,y_pred):\n",
    "        return (y_pred == y_true).mean()\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.training_data = X\n",
    "        self.training_labels = y\n",
    "        return self\n",
    "    \n",
    "    def nearest_neighbors(self, X):\n",
    "        nearest_indices = np.zeros(shape=(X.shape[0], \n",
    "                                          self.k_neighbors), dtype=np.int)-1\n",
    "        nearest_distances = np.zeros(shape=(X.shape[0], \n",
    "                                            self.k_neighbors), dtype=np.int)-1 \n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            distances = self.distance(X[i], self.training_data,\"distance\")\n",
    "            indexes = np.argsort(distances)[:self.k_neighbors]\n",
    "            nearest_indices[i] = indexes\n",
    "            nearest_distances[i] = distances[indexes]\n",
    "            \n",
    "        return (nearest_indices, nearest_distances)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(shape=(X.shape[0],))\n",
    "        indices_distances = self.nearest_neighbors(X)\n",
    "        y_labels = self.training_labels[indices_distances[0]]\n",
    "        distances = indices_distances[1]\n",
    "        \n",
    "        if self.d_type == \"uniform\":\n",
    "            for i in range(X.shape[0]):\n",
    "                y[i] = np.argmax(np.bincount((y_labels[i])))\n",
    "            return y\n",
    "        else:\n",
    "            for i in range(X.shape[0]):\n",
    "                counts = np.bincount(y_labels[i])\n",
    "                weighted_sum = counts[y_labels[i]] * distances[i]\n",
    "                y[i] = y_labels[i][np.argmax(weighted_sum)]\n",
    "            return y\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        acc = self.accuracy(y, y_pred)\n",
    "        loss = np.linalg.norm(y - y_pred, ord=self.p)\n",
    "        scores_count = {\"acc\":acc, \"loss\":loss}\n",
    "        return scores_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set best hyperparameters\n",
    "np.random.seed(42) \n",
    "\n",
    "# Reload data\n",
    "subsample_rate = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "X_train, _, y_train, _ = train_test_split(X_train, y_train, stratify=y_train, train_size=subsample_rate, random_state=42)\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, stratify=y_test, train_size=subsample_rate, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Use Homegrown knn\n",
    "knn_scratch = KNN(k_neighbors=8, p=1, d_type='weighted')   \n",
    "knn_scratch.fit(X_train, y_train.to_numpy()) \n",
    "train_score = knn_scratch.score(X_train,y_train)\n",
    "test_score = knn_scratch.score(X_test,y_test.to_numpy())\n",
    "y_pred_train = knn_scratch.predict(X_train)\n",
    "trainAcc = knn_scratch.score(y_train.to_numpy(), y_pred_train)\n",
    "y_pred_test = knn_scratch.predict(X_test)\n",
    "testAcc = knn_scratch.score(y_test.to_numpy(), y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc = knn_scratch.score(y_train.to_numpy(), y_pred_train)\n",
    "y_pred_test = knn_scratch.predict(X_test)\n",
    "testAcc = knn_scratch.score(y_test.to_numpy(), y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>K (Neighbors)</th>\n",
       "      <th>P (Scoring Metric)</th>\n",
       "      <th>Weights</th>\n",
       "      <th>Training Accuracy Score</th>\n",
       "      <th>Testing Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.998771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KNN Classifier Homegrown</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model K (Neighbors) P (Scoring Metric)   Weights  \\\n",
       "0            KNN Classifier             8                  1  distance   \n",
       "1  KNN Classifier Homegrown             8                  1  distance   \n",
       "\n",
       "   Training Accuracy Score  Testing Accuracy Score  \n",
       "0                 0.999605                0.998771  \n",
       "1                 1.000000                0.998244  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[len(results)] = [\"KNN Classifier Homegrown\", knn_gs.best_params_['knn__n_neighbors'],knn_gs.best_params_['knn__p'],\n",
    "                             knn_gs.best_params_['knn__weights'],trainAcc[\"acc\"],testAcc[\"acc\"]]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our homegrown KNN performed better on the training data compared to the KNN Classifer with SkLearn and the testing data from KNN Homegrown. The testing data from KNN Homegrown performed slightly worses compared to SKLearn, but it is pretty close! This shows you can build comparable models from scratch rather than using libraries (if you so choose to!)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
